{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This notebook shows how to use the distributed environment in the `DistributedJobs` module, which leverages the base Julia `Distributed` package to run jobs across multiple processes. Each job is just a function that takes an `Array` input and produces an `Array` output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Distributed Environment\n",
    "First define the number of processes to be used and include the required modules in each of the processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Int64}:\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the number of processes\n",
    "NUM_PROCS = 4\n",
    "\n",
    "# Set the number of processes to use for parallel computing\n",
    "using Distributed\n",
    "addprocs(NUM_PROCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add packages to all processes\n",
    "@everywhere include(\"../src/industrial_stats.jl\")\n",
    "@everywhere using .IndustrialStats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Distributed Job\n",
    "Suppose I wish to run an optimization algorithm against $10,000$ randomly initialized designs on the simplex and I want to spread the computing out over all four of my available processors. To do this I can generate large batches of designs and then optimize over those batches. If I choose a batch size of $500$, for example, then each processor will handle $5=(10,000/(4\\cdot 500))$ batches.\n",
    "\n",
    "In addition to choosing the batch size, I must provide a function that generates batches and a function that processes them, all inside of an `@everywhere` block to ensure these functions are available on every process. \n",
    "\n",
    "For this example, I will use some existing code from the repository to generate mixture designs for a first order Scheffe model; the actual handlers and generators can be anything as long as they operate on Julia `Array`s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Data Generator and Job Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere begin \n",
    "    # Returns a function that produces batch_size randomly initialized mixture designs\n",
    "    function create_design_generator(N, K, model_builder; batch_size=50)\n",
    "        # Init is a function that produces batch_sizexNxK tensors\n",
    "        init = IndustrialStats.DesignInitializer.initializer(N, K, model_builder; type = \"mixture\")\n",
    "\n",
    "        # Each time the generator is invoked, it will in turn invoke the init function to create a new batch\n",
    "        return () -> init(batch_size)\n",
    "    end\n",
    "\n",
    "    # Simpler generator example for basic uniform samples \n",
    "    function create_random_generator(N, K, batch_size)\n",
    "        return () => rand(batch_size, N, K)\n",
    "    end\n",
    "\n",
    "    # Stand-in optimizer function\n",
    "    # Replace with any function that accepts Array input\n",
    "    function my_optimizer(data::Array)\n",
    "        return data\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create & Run Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure experiment settings\n",
    "N = 7\n",
    "K = 3\n",
    "\n",
    "# Using the first-order scheffe implementation in the ModelBuilder module\n",
    "model_builder = IndustrialStats.ModelBuilder.scheffe(1)\n",
    "\n",
    "# Define batch size\n",
    "num_samples = 10_000\n",
    "batch_size = 500\n",
    "\n",
    "# Define data output location\n",
    "path_prefix = \"../data\"\n",
    "\n",
    "# Function that maps indices to Job structs\n",
    "job_creator = (idx) -> \n",
    "    IndustrialStats.DistributedJobs.create_job(\n",
    "        my_optimizer, \n",
    "        create_design_generator(N, K, model_builder; batch_size = 500); name = \"compute_job_$idx\"\n",
    "    )\n",
    "\n",
    "# Create vector of jobs\n",
    "jobs = map(job_creator, 1:(num_samples / batch_size))\n",
    "\n",
    "# Run jobs\n",
    "results = IndustrialStats.DistributedJobs.run_jobs(jobs; path_prefix=path_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Analyze\n",
    "The stored data can be loaded for analysis using HDF5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 7, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = IndustrialStats.DistributedJobs.load_and_concatenate(results)\n",
    "size(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.5",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
